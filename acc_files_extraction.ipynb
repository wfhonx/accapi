{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "450af8c0-c877-4394-9d24-a4a784be0d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Imports and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e83dd81a-ebe5-4553-84b4-893ba2a15ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "import time\n",
    "import pandas as pd                                     # Store and process tabular data in dataframes\n",
    "import requests                                         # Execute HTTP requests. GET requests in this file.\n",
    "from requests.adapters import HTTPAdapter               # Customize the HTTP adapter used by the requests session\n",
    "from requests.packages.urllib3.util.retry import Retry  # Retry method to define custom retry strategy\n",
    "#from tqdm.notebook import trange, tqdm                 # Library for progress bar\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44c604bd-8be9-4bc4-bebd-4f1db464d0c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### GLOBAL VARIABLES\n",
    "# Table names in the catalog\n",
    "table_name_in_catalog1 = \"dev.dept.acc_folder1\"\n",
    "table_name_in_catalog2 = \"dev.dept.acc_folder2\"\n",
    "\n",
    "# URL to request access token\n",
    "ACCESS_TOKEN_URL = \"OAuth2 bearer token URL\"\n",
    "\n",
    "# ACC project id\n",
    "PROJECT_ID = \"project_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b08a7bb-b130-4633-acaf-749976a28c7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8502bae5-eac0-4d1f-a533-861ea8cb43ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getAccessToken():\n",
    "    \"\"\"Get access token for authorization\n",
    "    \n",
    "    Returns:\n",
    "        str: access token string\n",
    "    \"\"\"\n",
    "#    return http.get(ACCESS_TOKEN_URL).json()[\"access_token\"]\n",
    "    return requests.get(ACCESS_TOKEN_URL).json()[\"access_token\"]\n",
    "\n",
    "\n",
    "def getAPIResponse(folder_id,page_num=0):\n",
    "    \"\"\"Get single page or multi-page response object from API based on result pagination.\n",
    "\n",
    "    Args:\n",
    "        folder_id (str): id of the current folder\n",
    "        page_num (int, optional): current page number for paginated result. Defaults to 0 in case of no pagination.\n",
    "\n",
    "    Returns:\n",
    "        JSON obj: JSON object in response from GET request\n",
    "    \"\"\"\n",
    "#    temp_count = 0\n",
    "    if page_num == 0:\n",
    "        url = f\"https://developer.api.autodesk.com/data/v1/projects/{PROJECT_ID}/folders/{folder_id}/contents\"\n",
    "    else:\n",
    "        url = f\"https://developer.api.autodesk.com/data/v1/projects/{PROJECT_ID}/folders/{folder_id}/contents?page%5Bnumber%5D={page_num}&page%5Blimit%5D=200\"\n",
    "\n",
    "    header = {\"Authorization\": f\"Bearer {getAccessToken()}\"}\n",
    "    response = requests.get(url, headers=header)\n",
    "\n",
    "    while response.status_code != 200:\n",
    "        header = {\"Authorization\": f\"Bearer {getAccessToken()}\"}\n",
    "        response = requests.get(url, headers=header)\n",
    "        if response.status_code not in [0, 200]:\n",
    "            print(response.status_code)\n",
    "            time.sleep(1)\n",
    "#            temp_count += 1\n",
    "#            if temp_count == 5:\n",
    "#                exit\n",
    "\n",
    "    return response\n",
    "#    return http.get(url, headers=header)\n",
    "\n",
    "\n",
    "def getItemAttr(currData, currFolderPath):\n",
    "    \"\"\"Extract item attributes and metadata\n",
    "\n",
    "    Args:\n",
    "        currData (dict): json data in dict format\n",
    "        currFolderPath (str): current folder path\n",
    "\n",
    "    Returns:\n",
    "        list: list of attributes of an item\n",
    "    \"\"\"\n",
    "    folder_path = f\"{currFolderPath}/\"\n",
    "    file_displayName = currData[\"attributes\"][\"displayName\"]\n",
    "    file_url = currData[\"links\"][\"webView\"][\"href\"]\n",
    "    file_version = currData[\"relationships\"][\"tip\"][\"data\"][\"id\"][-1]\n",
    "    file_last_modified = currData[\"attributes\"][\"lastModifiedTime\"]\n",
    "    file_last_modified_by = currData[\"attributes\"][\"lastModifiedUserName\"]\n",
    "    file_created = currData[\"attributes\"][\"createTime\"]\n",
    "    file_created_by = currData[\"attributes\"][\"createUserName\"]\n",
    "    return [folder_path, file_displayName, file_url, file_version, file_last_modified, file_last_modified_by, file_created,file_created_by]\n",
    "\n",
    "\n",
    "def get_all_files(folder_id, folderPath):\n",
    "    \"\"\"Primary function to recursively extract all the files from the target folder and subfolders within\n",
    "\n",
    "    Args:\n",
    "        folder_id (str): current id of the target folder\n",
    "        folderPath (str): current path of the folder in storage system\n",
    "\n",
    "    Returns:\n",
    "        list: list of lists containing attributes/metadata of extracted files\n",
    "    \"\"\"\n",
    "    # params = {\"filter[extension.type]\": \"items:autodesk.bim360:File\"}   # Filter parameter for 'search' endpoint\n",
    "    \n",
    "    # get response obj from API for folder with folder id 'folder_id'\n",
    "    response = getAPIResponse(folder_id)\n",
    "    files = []\n",
    "\n",
    "    # Check if the GET request was successful\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        # Check if the result is paginated\n",
    "        if \"next\" in list(response.json()[\"links\"]):\n",
    "            page_num = 0\n",
    "            while True:\n",
    "                # Get API response for specified folder id with page number in case of pagination\n",
    "                multiPageResponse = getAPIResponse(folder_id, page_num).json()\n",
    "                \n",
    "                # Iterate through all the items in the page\n",
    "                for item in multiPageResponse[\"data\"]:\n",
    "                    \n",
    "                    # Check for type:item (file)\n",
    "                    if item[\"type\"] == \"items\":\n",
    "                        # Extract file attributes\n",
    "                        files.append(getItemAttr(item, folderPath))\n",
    "\n",
    "                    # Check for type:folder and recursively call for subfolders if true\n",
    "                    if item[\"type\"] == \"folders\":\n",
    "                        subFolderPath = f\"{folderPath}/{item['attributes']['displayName']}\"\n",
    "                        files.extend(get_all_files(item[\"id\"],subFolderPath))\n",
    "                \n",
    "                if \"next\" in list(multiPageResponse[\"links\"]):\n",
    "                    # Increment page number by 1 if \"next\" found in list of keys, which means the current page was not the last\n",
    "                    page_num += 1\n",
    "                else:\n",
    "                    # Break the while loop if \"next\" not found in the list of keys, which means the current page was the last\n",
    "                    break\n",
    "        \n",
    "        else:\n",
    "            # Convert the response object into json format in case the result is not paginated\n",
    "            singlePageResponse = response.json()\n",
    "            \n",
    "            # Iterate through all the items\n",
    "            for item in singlePageResponse[\"data\"]:\n",
    "                \n",
    "                # Check for type:item (file)\n",
    "                if item[\"type\"] == \"items\":\n",
    "                    # Extract file attributes\n",
    "                    files.append(getItemAttr(item, folderPath))\n",
    "\n",
    "                # Check for type:folder\n",
    "                if item[\"type\"] == \"folders\":\n",
    "                    # Define the folder path for the folder subfolder found\n",
    "                    subFolderPath = f\"{folderPath}/{item['attributes']['displayName']}\"\n",
    "                    # Recursively call the function itself with folder id and path of the current folder\n",
    "                    files.extend(get_all_files(item[\"id\"],subFolderPath))\n",
    "\n",
    "        return files\n",
    "    \n",
    "    else:\n",
    "        # In case the GET request fails\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e2ce001-875b-4e72-befb-74a60957ce7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c5138b4-dacc-49b1-a68a-f9f1501d6cf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of dictionary items containing folder id, folder path and output file name for each folder\n",
    "folders = [\n",
    "    {\n",
    "        \"id\":\"urn of acc folder1\",\n",
    "        \"path\":\"Folder/Path/1\",\n",
    "        \"database\":table_name_in_catalog1\n",
    "        },\n",
    "    {\n",
    "        \"id\":\"urn of acc folder2\",\n",
    "        \"path\":\"Folder/Path/2\",\n",
    "        \"database\":table_name_in_catalog2\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Dataframe Schema for Spark\n",
    "schema = StructType([\n",
    "    StructField(\"folder_path\", StringType(), True),\n",
    "    StructField(\"file_displayName\", StringType(), True),\n",
    "    StructField(\"file_url\", StringType(), True),\n",
    "    StructField(\"file_version\", StringType(), True),\n",
    "    StructField(\"file_last_modified\", StringType(), True),\n",
    "    StructField(\"file_last_modified_by\", StringType(), True),\n",
    "    StructField(\"file_created\", StringType(), True),\n",
    "    StructField(\"file_created_by\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ace7068e-cde9-4bb2-b450-04f1bcee3bc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through the list of target folders\n",
    "for folder in folders:\n",
    "    # Generate list of files and its attributes within specified folder and subfolder within\n",
    "    files_list = get_all_files(folder[\"id\"], folder[\"path\"])\n",
    "    print(f\"{folder['path'].split('/')[-1]}: {len(files_list)}\")\n",
    "\n",
    "    # Convert the list of files to a dataframe\n",
    "    files_df = spark.createDataFrame(files_list, schema=schema)\n",
    "    #[\"folder_path\",\"file_displayName\",\"file_url\",\"file_version\",\"file_last_modified\",\"file_last_modified_by\",\"file_created\", \"file_created_by\"])\n",
    "    print(\"DataFrame Created\")\n",
    "\n",
    "    # Save data to databricks table\n",
    "    files_df.write.option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(folder['database'])\n",
    "    print(\"Table saved!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ACC Files Extraction",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
